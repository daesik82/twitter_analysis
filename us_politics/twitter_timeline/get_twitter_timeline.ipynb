{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloads - only to it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing packages\n",
    "# non-conda packages\n",
    "! pip install twitter\n",
    "! pip install -U nltk\n",
    "! pip install -U textblob\n",
    "! pip install networkx\n",
    "! pip install gender-guesser\n",
    "\n",
    "# conda packages\n",
    "! conda install -c conda-forge -y wordcloud\n",
    "    \n",
    "# additional downloads    \n",
    "! python -m textblob.download_corpora\n",
    "! python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import codecs\n",
    "from collections import Counter\n",
    "from datetime import date, datetime, timedelta, timezone\n",
    "import pickle\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import twitter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrep twitters\n",
    "df = pd.read_excel('rep_twitters.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrep_twhandles = list(df.tw_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hrep_twhandles.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(hrep_twhandles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('sen_list_116.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hawley Press Office</td>\n",
       "      <td>@SenHawleyPress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mike Braun</td>\n",
       "      <td>@SenatorBraun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>@SenatorRomney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      screen_name\n",
       "0  Hawley Press Office  @SenHawleyPress\n",
       "1           Mike Braun    @SenatorBraun\n",
       "2          Mitt Romney   @SenatorRomney"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_twhandles = list(df1.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sen_twhandles.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(sen_twhandles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up text \n",
    "def cleanse_text(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    text = text.replace(\"\\t\", \"\")\n",
    "    text = text.replace(\"\\\"\", \"\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def save_latest_id(string):\n",
    "    with open('latest_id.txt', 'wb') as f:\n",
    "        pickle.dump(string, f)\n",
    "        \n",
    "def load_latest_id(pickle_file):\n",
    "    with open('latest_id.txt', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "CONSUMER_KEY = \"LH4kuDFYDbitBOHXX0dAiXjUk\"\n",
    "CONSUMER_SECRET = \"wiucSGOJkhhhUqtMgvWKjuengTMvPDVDksluyTqUo5YEVpDxWh\"\n",
    "ACCESS_TOKEN = \"166588006-si4UHhFeVgMuo3yxBXMGbsJFY5tmeRngkjgbmbMX\"\n",
    "ACCESS_TOKEN_SECRET = \"vawC4Ui5sj4RqbDpwA6fsjM5fOSPLYxccHWXMkvUtKZBK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a connectino to Twitter \n",
    "auth = twitter.oauth.OAuth(ACCESS_TOKEN, ACCESS_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Twitter Search - User Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"RepAOC\"\n",
    "search_date = datetime.now(pytz.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_week = search_date - timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_result = twitter_api.statuses.user_timeline(screen_name=\"RepAOC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timeline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline_result[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latest_id(timeline_result[0]['id_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to CSV \n",
    "file = f\"search_data_{screen_name}_{search_date}.csv\"\n",
    "with open(file=file, mode=\"w\", encoding=\"utf8\") as fw:\n",
    "    fw.write(\"id\\t\" + \n",
    "             \"created_at\\t\" + \n",
    "             \"text\\t\" + \n",
    "             \"hashtags\\t\" + \n",
    "             \"symbols\\t\" +\n",
    "             \"user_mentions\\t\" + \n",
    "             \"user_id\\t\" + \n",
    "             \"user_name\\t\" + \n",
    "             \"user_screen_name\\t\" + \n",
    "             \"user_followers_count\\t\" + \n",
    "             \"retweet_count\\t\" + \n",
    "             \"favorite_count\\n\")\n",
    "    for tweet in timeline_result:\n",
    "        fw.write(tweet['id_str'] + '\\t')\n",
    "        fw.write(tweet['created_at'] + '\\t')\n",
    "        fw.write(cleanse_text(tweet['text']) + '\\t')\n",
    "        fw.write(str(tweet['entities']['hashtags']) + '\\t')\n",
    "        fw.write(str(tweet['entities']['symbols']) + '\\t')\n",
    "        fw.write(str(tweet['entities']['user_mentions']) + '\\t')\n",
    "        fw.write(tweet['user']['id_str'] + '\\t')\n",
    "        fw.write(tweet['user']['name'] + '\\t')\n",
    "        fw.write(tweet['user']['screen_name'] + '\\t')\n",
    "        fw.write(str(tweet['user']['followers_count']) + '\\t')\n",
    "        fw.write(str(tweet['retweet_count']) + '\\t')\n",
    "        fw.write(str(tweet['favorite_count']) + '\\t')\n",
    "        fw.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file as a pandas df\n",
    "df = pd.read_csv(file, sep=\"\\t\", header=0, parse_dates=[1], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1096112733400035328</td>\n",
       "      <td>2019-02-14 18:23:35+00:00</td>\n",
       "      <td>A joint statement from the offices of @Ilhan @...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'Ilhan', 'name': 'Rep. Ilhan ...</td>\n",
       "      <td>1079104563280527364</td>\n",
       "      <td>Rep. Alexandria Ocasio-Cortez</td>\n",
       "      <td>RepAOC</td>\n",
       "      <td>124513</td>\n",
       "      <td>398</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1093582852917219337</td>\n",
       "      <td>2019-02-07 18:50:44+00:00</td>\n",
       "      <td>Proud to stand with @SenMarkey and over 60 Ori...</td>\n",
       "      <td>[{'text': 'GreenNewDeal', 'indices': [92, 105]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'SenMarkey', 'name': 'Ed Mark...</td>\n",
       "      <td>1079104563280527364</td>\n",
       "      <td>Rep. Alexandria Ocasio-Cortez</td>\n",
       "      <td>RepAOC</td>\n",
       "      <td>124513</td>\n",
       "      <td>1380</td>\n",
       "      <td>4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1090471469170245637</td>\n",
       "      <td>2019-01-30 04:47:12+00:00</td>\n",
       "      <td>RT @RepRashida: Today was my first hearing on ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'RepRashida', 'name': 'Congre...</td>\n",
       "      <td>1079104563280527364</td>\n",
       "      <td>Rep. Alexandria Ocasio-Cortez</td>\n",
       "      <td>RepAOC</td>\n",
       "      <td>124513</td>\n",
       "      <td>2212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1090471337724964870</td>\n",
       "      <td>2019-01-30 04:46:41+00:00</td>\n",
       "      <td>Today @OversightDems held its first-ever heari...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'OversightDems', 'name': 'Ove...</td>\n",
       "      <td>1079104563280527364</td>\n",
       "      <td>Rep. Alexandria Ocasio-Cortez</td>\n",
       "      <td>RepAOC</td>\n",
       "      <td>124513</td>\n",
       "      <td>349</td>\n",
       "      <td>2697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088209102722031616</td>\n",
       "      <td>2019-01-23 22:57:22+00:00</td>\n",
       "      <td>The post-its outside our office are growing üíú ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1079104563280527364</td>\n",
       "      <td>Rep. Alexandria Ocasio-Cortez</td>\n",
       "      <td>RepAOC</td>\n",
       "      <td>124513</td>\n",
       "      <td>477</td>\n",
       "      <td>5267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                created_at  \\\n",
       "0  1096112733400035328 2019-02-14 18:23:35+00:00   \n",
       "1  1093582852917219337 2019-02-07 18:50:44+00:00   \n",
       "2  1090471469170245637 2019-01-30 04:47:12+00:00   \n",
       "3  1090471337724964870 2019-01-30 04:46:41+00:00   \n",
       "4  1088209102722031616 2019-01-23 22:57:22+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  A joint statement from the offices of @Ilhan @...   \n",
       "1  Proud to stand with @SenMarkey and over 60 Ori...   \n",
       "2  RT @RepRashida: Today was my first hearing on ...   \n",
       "3  Today @OversightDems held its first-ever heari...   \n",
       "4  The post-its outside our office are growing üíú ...   \n",
       "\n",
       "                                           hashtags symbols  \\\n",
       "0                                                []      []   \n",
       "1  [{'text': 'GreenNewDeal', 'indices': [92, 105]}]      []   \n",
       "2                                                []      []   \n",
       "3                                                []      []   \n",
       "4                                                []      []   \n",
       "\n",
       "                                       user_mentions              user_id  \\\n",
       "0  [{'screen_name': 'Ilhan', 'name': 'Rep. Ilhan ...  1079104563280527364   \n",
       "1  [{'screen_name': 'SenMarkey', 'name': 'Ed Mark...  1079104563280527364   \n",
       "2  [{'screen_name': 'RepRashida', 'name': 'Congre...  1079104563280527364   \n",
       "3  [{'screen_name': 'OversightDems', 'name': 'Ove...  1079104563280527364   \n",
       "4                                                 []  1079104563280527364   \n",
       "\n",
       "                       user_name user_screen_name  user_followers_count  \\\n",
       "0  Rep. Alexandria Ocasio-Cortez           RepAOC                124513   \n",
       "1  Rep. Alexandria Ocasio-Cortez           RepAOC                124513   \n",
       "2  Rep. Alexandria Ocasio-Cortez           RepAOC                124513   \n",
       "3  Rep. Alexandria Ocasio-Cortez           RepAOC                124513   \n",
       "4  Rep. Alexandria Ocasio-Cortez           RepAOC                124513   \n",
       "\n",
       "   retweet_count  favorite_count  \n",
       "0            398            1397  \n",
       "1           1380            4560  \n",
       "2           2212               0  \n",
       "3            349            2697  \n",
       "4            477            5267  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenization & tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df.text.apply(lambda x:TextBlob(x).tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df.text.apply(lambda x:x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'tags', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "local_stopwords = [\"@\", \"&\", \"‚Äò\", \"‚Äô\", \"‚Äú\", \"‚Äù\", \"‚Ä¶\", \"'\", \"\", \"'s\", \"''\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for tags in df['tags']:\n",
    "    word_set = set()\n",
    "    \n",
    "    for item in tags:\n",
    "        word = item[0].lower()\n",
    "        \n",
    "        if word in (global_stopwords + local_stopwords):\n",
    "            continue\n",
    "        else:\n",
    "            word_set.add(word)\n",
    "            \n",
    "    counter.update(word_set)\n",
    "\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in df['tokens']:\n",
    "    tokens_set = set()\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        \n",
    "        if token in (global_stopwords + local_stopwords):\n",
    "            continue\n",
    "        else:\n",
    "            tokens_set.add(token)\n",
    "    \n",
    "    counter.update(tokens_set)\n",
    "        \n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For continuous data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"RepAOC\"\n",
    "search_date = date.today().strftime(\"%m-%d-%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_result = twitter_api.statuses.user_timeline(screen_name=\"RepAOC\", \n",
    "                                                     since_id=load_latest_id('latest_id.txt'),\n",
    "                                                     count='100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Twitter timelines for multiple screen names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in Rep Twitter data\n",
    "df_rep_twitters = pd.read_excel('rep_twitters.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_names = df_rep_twitters['tw_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(screen_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DF for result data\n",
    "df_twitter_results = pd.DataFrame(columns=['id_str', 'created_at', 'text', 'hashtags', 'symbols', 'user_mentions',\n",
    "                                           'user_id', 'user_name', 'user_screen_name', 'user_followers_count', \n",
    "                                           'retweet_count', 'favorite_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_twitter_results = {'id_str': [], \n",
    "                       'created_at': [], \n",
    "                       'text': [], \n",
    "                       'hashtags': [], \n",
    "                       'symbols': [], \n",
    "                       'user_mentions': [],\n",
    "                       'user_id': [], \n",
    "                       'user_name': [], \n",
    "                       'user_screen_name': [], \n",
    "                       'user_followers_count': [], \n",
    "                       'retweet_count': [], \n",
    "                       'favorite_count': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in screen_names:\n",
    "    t_result = twitter_api.statuses.user_timeline(screen_name=item, count=20)\n",
    "    for tweet in t_result:\n",
    "        dict_twitter_results['id_str'].append(tweet['id_str'])\n",
    "        dict_twitter_results['created_at'].append(tweet['created_at'])\n",
    "        dict_twitter_results['text'].append(tweet['text'])\n",
    "        dict_twitter_results['hashtags'].append(str(tweet['entities']['hashtags']))\n",
    "        dict_twitter_results['symbols'].append(str(tweet['entities']['symbols']))\n",
    "        dict_twitter_results['user_mentions'].append(str(tweet['entities']['user_mentions']))\n",
    "        dict_twitter_results['user_id'].append(tweet['user']['id_str'])\n",
    "        dict_twitter_results['user_name'].append(tweet['user']['name'])\n",
    "        dict_twitter_results['user_screen_name'].append(tweet['user']['screen_name'])\n",
    "        dict_twitter_results['user_followers_count'].append(str(tweet['user']['followers_count']))\n",
    "        dict_twitter_results['retweet_count'].append(str(tweet['retweet_count']))\n",
    "        dict_twitter_results['favorite_count'].append(str(tweet['favorite_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw = pd.DataFrame.from_dict(dict_twitter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-02-18 16:30:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df_tw['created_at']\n",
    "s2 = pd.to_datetime(s, infer_datetime_format=True)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw['post_date'] = s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>post_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1097533701775187968</td>\n",
       "      <td>Mon Feb 18 16:30:00 +0000 2019</td>\n",
       "      <td>‚ÄúIf the Green New Deal becomes a reality, the ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2962891515</td>\n",
       "      <td>Rep. Ralph Abraham</td>\n",
       "      <td>RepAbraham</td>\n",
       "      <td>16026</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-02-18 16:30:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1097190187942043648</td>\n",
       "      <td>Sun Feb 17 17:45:00 +0000 2019</td>\n",
       "      <td>If we don‚Äôt stand for life, who will? While ot...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2962891515</td>\n",
       "      <td>Rep. Ralph Abraham</td>\n",
       "      <td>RepAbraham</td>\n",
       "      <td>16026</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>2019-02-17 17:45:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str                      created_at  \\\n",
       "0  1097533701775187968  Mon Feb 18 16:30:00 +0000 2019   \n",
       "1  1097190187942043648  Sun Feb 17 17:45:00 +0000 2019   \n",
       "\n",
       "                                                text hashtags symbols  \\\n",
       "0  ‚ÄúIf the Green New Deal becomes a reality, the ...       []      []   \n",
       "1  If we don‚Äôt stand for life, who will? While ot...       []      []   \n",
       "\n",
       "  user_mentions     user_id           user_name user_screen_name  \\\n",
       "0            []  2962891515  Rep. Ralph Abraham       RepAbraham   \n",
       "1            []  2962891515  Rep. Ralph Abraham       RepAbraham   \n",
       "\n",
       "  user_followers_count retweet_count favorite_count                 post_date  \n",
       "0                16026             4             10 2019-02-18 16:30:00+00:00  \n",
       "1                16026             8             25 2019-02-17 17:45:00+00:00  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw.to_csv('twitter_results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw_week = df_tw[(df_tw['post_date'] > target_week)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_tw_week['tags'] = df_tw_week['text'].apply(lambda x: TextBlob(x).tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ÄúIf the Green New Deal becomes a reality, the ...</td>\n",
       "      <td>[(‚Äú, NN), (If, IN), (the, DT), (Green, NNP), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If we don‚Äôt stand for life, who will? While ot...</td>\n",
       "      <td>[(If, IN), (we, PRP), (don, VBP), (‚Äô, JJ), (t,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ‚ÄúIf the Green New Deal becomes a reality, the ...   \n",
       "1  If we don‚Äôt stand for life, who will? While ot...   \n",
       "\n",
       "                                                tags  \n",
       "0  [(‚Äú, NN), (If, IN), (the, DT), (Green, NNP), (...  \n",
       "1  [(If, IN), (we, PRP), (don, VBP), (‚Äô, JJ), (t,...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tw_week[['text', 'tags']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_tw_week['tokens'] = df_tw_week['text'].apply(lambda x: re.sub('[^\\w\\s]', '', x).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_tw_week['retweet'] = df_tw_week['tokens'].apply(lambda x: 1 if x[0] == 'RT' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ÄúIf the Green New Deal becomes a reality, the ...</td>\n",
       "      <td>[(‚Äú, NN), (If, IN), (the, DT), (Green, NNP), (...</td>\n",
       "      <td>[If, the, Green, New, Deal, becomes, a, realit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If we don‚Äôt stand for life, who will? While ot...</td>\n",
       "      <td>[(If, IN), (we, PRP), (don, VBP), (‚Äô, JJ), (t,...</td>\n",
       "      <td>[If, we, dont, stand, for, life, who, will, Wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anyone who thinks our crisis at the border is ...</td>\n",
       "      <td>[(Anyone, NN), (who, WP), (thinks, VBZ), (our,...</td>\n",
       "      <td>[Anyone, who, thinks, our, crisis, at, the, bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚ÄúRepublican Rep. Ralph Abraham isn't going to ...</td>\n",
       "      <td>[(‚Äú, JJ), (Republican, NNP), (Rep., NNP), (Ral...</td>\n",
       "      <td>[Republican, Rep, Ralph, Abraham, isnt, going,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you to @WashTimes for allowing @SenJohnK...</td>\n",
       "      <td>[(Thank, NNP), (you, PRP), (to, TO), (@, VB), ...</td>\n",
       "      <td>[Thank, you, to, WashTimes, for, allowing, Sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I‚Äôm thankful to have @SecretarySonny‚Äôs support...</td>\n",
       "      <td>[(I, PRP), (‚Äô, VBP), (m, RB), (thankful, JJ), ...</td>\n",
       "      <td>[Im, thankful, to, have, SecretarySonnys, supp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This week, we salute the more than 9 million v...</td>\n",
       "      <td>[(This, DT), (week, NN), (we, PRP), (salute, V...</td>\n",
       "      <td>[This, week, we, salute, the, more, than, 9, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If President Trump needs to declare a #Nationa...</td>\n",
       "      <td>[(If, IN), (President, NNP), (Trump, NNP), (ne...</td>\n",
       "      <td>[If, President, Trump, needs, to, declare, a, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I voted NO. This bill limits the number of ill...</td>\n",
       "      <td>[(I, PRP), (voted, VBD), (NO, NNP), (This, DT)...</td>\n",
       "      <td>[I, voted, NO, This, bill, limits, the, number...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>As a pilot, I‚Äôve seen firsthand ‚Äì from the coc...</td>\n",
       "      <td>[(As, IN), (a, DT), (pilot, NN), (I, PRP), (‚Äô,...</td>\n",
       "      <td>[As, a, pilot, Ive, seen, firsthand, , from, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I couldn‚Äôt agree more with my colleague and fe...</td>\n",
       "      <td>[(I, PRP), (couldn, VBP), (‚Äô, JJ), (t, NN), (a...</td>\n",
       "      <td>[I, couldnt, agree, more, with, my, colleague,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The #GreenNewDeal is a socialist‚Äôs wish list. ...</td>\n",
       "      <td>[(The, DT), (GreenNewDeal, NNP), (is, VBZ), (a...</td>\n",
       "      <td>[The, GreenNewDeal, is, a, socialists, wish, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Happy birthday to one of America‚Äôs greatest le...</td>\n",
       "      <td>[(Happy, JJ), (birthday, NN), (to, TO), (one, ...</td>\n",
       "      <td>[Happy, birthday, to, one, of, Americas, great...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.@NationalSheriff and @MCSheriffs have called ...</td>\n",
       "      <td>[(@, NN), (NationalSheriff, NNP), (and, CC), (...</td>\n",
       "      <td>[NationalSheriff, and, MCSheriffs, have, calle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Congratulations Charlotte for a great NBA All ...</td>\n",
       "      <td>[(Congratulations, NNS), (Charlotte, NNP), (fo...</td>\n",
       "      <td>[Congratulations, Charlotte, for, a, great, NB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @nowthisnews: Nearly 1,200 children were ki...</td>\n",
       "      <td>[(RT, NNP), (@, NNP), (nowthisnews, NNS), (Nea...</td>\n",
       "      <td>[RT, nowthisnews, Nearly, 1200, children, were...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Today for #BlackHistoryMonth we honor, Dominiq...</td>\n",
       "      <td>[(Today, NN), (for, IN), (BlackHistoryMonth, N...</td>\n",
       "      <td>[Today, for, BlackHistoryMonth, we, honor, Dom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>As the @NBAAllStar weekend kicks off tonight, ...</td>\n",
       "      <td>[(As, IN), (the, DT), (@, NNP), (NBAAllStar, N...</td>\n",
       "      <td>[As, the, NBAAllStar, weekend, kicks, off, ton...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>See my official statement on the bipartisan de...</td>\n",
       "      <td>[(See, VB), (my, PRP$), (official, JJ), (state...</td>\n",
       "      <td>[See, my, official, statement, on, the, bipart...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Happy Valentine's Day! https://t.co/7lNvUfR0yx</td>\n",
       "      <td>[(Happy, JJ), (Valentine, NNP), ('s, POS), (Da...</td>\n",
       "      <td>[Happy, Valentines, Day, httpstco7lNvUfR0yx]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Charities and places of worship shouldn‚Äôt have...</td>\n",
       "      <td>[(Charities, NNS), (and, CC), (places, NNS), (...</td>\n",
       "      <td>[Charities, and, places, of, worship, shouldnt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Republicans gave away over $1 TRILLION in tax ...</td>\n",
       "      <td>[(Republicans, NNPS), (gave, VBD), (away, RB),...</td>\n",
       "      <td>[Republicans, gave, away, over, 1, TRILLION, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RT @RepTedDeutch: Standing today and always wi...</td>\n",
       "      <td>[(RT, NNP), (@, NNP), (RepTedDeutch, NNP), (St...</td>\n",
       "      <td>[RT, RepTedDeutch, Standing, today, and, alway...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>House Democrats promised action and we promise...</td>\n",
       "      <td>[(House, NNP), (Democrats, NNPS), (promised, V...</td>\n",
       "      <td>[House, Democrats, promised, action, and, we, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RT @EdLaborCmte: The #PaycheckFairness Act cou...</td>\n",
       "      <td>[(RT, NNP), (@, NNP), (EdLaborCmte, NNP), (The...</td>\n",
       "      <td>[RT, EdLaborCmte, The, PaycheckFairness, Act, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Today for #BlackHistoryMonth we honor Ruby Bri...</td>\n",
       "      <td>[(Today, NN), (for, IN), (BlackHistoryMonth, N...</td>\n",
       "      <td>[Today, for, BlackHistoryMonth, we, honor, Rub...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Unmarked burial grounds are often discovered w...</td>\n",
       "      <td>[(Unmarked, VBN), (burial, JJ), (grounds, NNS)...</td>\n",
       "      <td>[Unmarked, burial, grounds, are, often, discov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>This bill will help communities preserve their...</td>\n",
       "      <td>[(This, DT), (bill, NN), (will, MD), (help, VB...</td>\n",
       "      <td>[This, bill, will, help, communities, preserve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>That‚Äôs why today, during #BlackHistoryMonth , ...</td>\n",
       "      <td>[(That, DT), (‚Äô, VBD), (s, JJ), (why, WRB), (t...</td>\n",
       "      <td>[Thats, why, today, during, BlackHistoryMonth,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The graves of African Americans have too frequ...</td>\n",
       "      <td>[(The, DT), (graves, NNS), (of, IN), (African,...</td>\n",
       "      <td>[The, graves, of, African, Americans, have, to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Standing with the members of the North Carolin...</td>\n",
       "      <td>[(Standing, VBG), (with, IN), (the, DT), (memb...</td>\n",
       "      <td>[Standing, with, the, members, of, the, North,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I know firsthand that these are some of the ke...</td>\n",
       "      <td>[(I, PRP), (know, VBP), (firsthand, VBP), (tha...</td>\n",
       "      <td>[I, know, firsthand, that, these, are, some, o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>During today‚Äôs hearing I asked questions about...</td>\n",
       "      <td>[(During, IN), (today, NN), (‚Äô, NNP), (s, NN),...</td>\n",
       "      <td>[During, todays, hearing, I, asked, questions,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9,268 people in North Carolina experience home...</td>\n",
       "      <td>[(9,268, CD), (people, NNS), (in, IN), (North,...</td>\n",
       "      <td>[9268, people, in, North, Carolina, experience...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Suppliers from nearly every state in the natio...</td>\n",
       "      <td>[(Suppliers, NNS), (from, IN), (nearly, RB), (...</td>\n",
       "      <td>[Suppliers, from, nearly, every, state, in, th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Mrs. Easterwood did a great job! https://t.co/...</td>\n",
       "      <td>[(Mrs., NNP), (Easterwood, NNP), (did, VBD), (...</td>\n",
       "      <td>[Mrs, Easterwood, did, a, great, job, httpstco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>The president wants to raid funding for our mi...</td>\n",
       "      <td>[(The, DT), (president, NN), (wants, VBZ), (to...</td>\n",
       "      <td>[The, president, wants, to, raid, funding, for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Proud to be a part of this group working to #K...</td>\n",
       "      <td>[(Proud, NN), (to, TO), (be, VB), (a, DT), (pa...</td>\n",
       "      <td>[Proud, to, be, a, part, of, this, group, work...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>The president‚Äôs inability to fulfill his campa...</td>\n",
       "      <td>[(The, DT), (president, NN), (‚Äô, NNP), (s, VBZ...</td>\n",
       "      <td>[The, presidents, inability, to, fulfill, his,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>https://t.co/h9MTeIoja3</td>\n",
       "      <td>[(https, NN), (//t.co/h9MTeIoja3, NN)]</td>\n",
       "      <td>[httpstcoh9MTeIoja3]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>RT @RepTedDeutch: Standing today and always wi...</td>\n",
       "      <td>[(RT, NNP), (@, NNP), (RepTedDeutch, NNP), (St...</td>\n",
       "      <td>[RT, RepTedDeutch, Standing, today, and, alway...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Immigrants: bad\\nWhite Collar Crime: okay\\n\\nS...</td>\n",
       "      <td>[(Immigrants, NNS), (bad, JJ), (White, NNP), (...</td>\n",
       "      <td>[Immigrants, bad\\nWhite, Collar, Crime, okay\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Our job was to reach a deal, not deliver a win...</td>\n",
       "      <td>[(Our, PRP$), (job, NN), (was, VBD), (to, TO),...</td>\n",
       "      <td>[Our, job, was, to, reach, a, deal, not, deliv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Proud to announce this federal funding to prov...</td>\n",
       "      <td>[(Proud, NN), (to, TO), (announce, VB), (this,...</td>\n",
       "      <td>[Proud, to, announce, this, federal, funding, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Happy #PresidentsDay, #GA12 https://t.co/qagMb...</td>\n",
       "      <td>[(Happy, JJ), (PresidentsDay, NNP), (GA12, NNP...</td>\n",
       "      <td>[Happy, PresidentsDay, GA12, httpstcoqagMbIxWri]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Take a look at my e-Newsletter to see what I d...</td>\n",
       "      <td>[(Take, VB), (a, DT), (look, NN), (at, IN), (m...</td>\n",
       "      <td>[Take, a, look, at, my, eNewsletter, to, see, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Late Wednesday evening, my colleagues and I we...</td>\n",
       "      <td>[(Late, JJ), (Wednesday, NNP), (evening, NN), ...</td>\n",
       "      <td>[Late, Wednesday, evening, my, colleagues, and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>I was very honored to join members of the Augu...</td>\n",
       "      <td>[(I, PRP), (was, VBD), (very, RB), (honored, V...</td>\n",
       "      <td>[I, was, very, honored, to, join, members, of,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Thirteen grandkids later and she‚Äôs still my fo...</td>\n",
       "      <td>[(Thirteen, NNP), (grandkids, NNS), (later, RB...</td>\n",
       "      <td>[Thirteen, grandkids, later, and, shes, still,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>On the heels of a very impressive January #Job...</td>\n",
       "      <td>[(On, IN), (the, DT), (heels, NNS), (of, IN), ...</td>\n",
       "      <td>[On, the, heels, of, a, very, impressive, Janu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   ‚ÄúIf the Green New Deal becomes a reality, the ...   \n",
       "1   If we don‚Äôt stand for life, who will? While ot...   \n",
       "2   Anyone who thinks our crisis at the border is ...   \n",
       "3   ‚ÄúRepublican Rep. Ralph Abraham isn't going to ...   \n",
       "4   Thank you to @WashTimes for allowing @SenJohnK...   \n",
       "5   I‚Äôm thankful to have @SecretarySonny‚Äôs support...   \n",
       "6   This week, we salute the more than 9 million v...   \n",
       "7   If President Trump needs to declare a #Nationa...   \n",
       "8   I voted NO. This bill limits the number of ill...   \n",
       "9   As a pilot, I‚Äôve seen firsthand ‚Äì from the coc...   \n",
       "10  I couldn‚Äôt agree more with my colleague and fe...   \n",
       "11  The #GreenNewDeal is a socialist‚Äôs wish list. ...   \n",
       "12  Happy birthday to one of America‚Äôs greatest le...   \n",
       "13  .@NationalSheriff and @MCSheriffs have called ...   \n",
       "20  Congratulations Charlotte for a great NBA All ...   \n",
       "21  RT @nowthisnews: Nearly 1,200 children were ki...   \n",
       "22  Today for #BlackHistoryMonth we honor, Dominiq...   \n",
       "23  As the @NBAAllStar weekend kicks off tonight, ...   \n",
       "24  See my official statement on the bipartisan de...   \n",
       "25     Happy Valentine's Day! https://t.co/7lNvUfR0yx   \n",
       "26  Charities and places of worship shouldn‚Äôt have...   \n",
       "27  Republicans gave away over $1 TRILLION in tax ...   \n",
       "28  RT @RepTedDeutch: Standing today and always wi...   \n",
       "29  House Democrats promised action and we promise...   \n",
       "30  RT @EdLaborCmte: The #PaycheckFairness Act cou...   \n",
       "31  Today for #BlackHistoryMonth we honor Ruby Bri...   \n",
       "32  Unmarked burial grounds are often discovered w...   \n",
       "33  This bill will help communities preserve their...   \n",
       "34  That‚Äôs why today, during #BlackHistoryMonth , ...   \n",
       "35  The graves of African Americans have too frequ...   \n",
       "36  Standing with the members of the North Carolin...   \n",
       "37  I know firsthand that these are some of the ke...   \n",
       "38  During today‚Äôs hearing I asked questions about...   \n",
       "39  9,268 people in North Carolina experience home...   \n",
       "40  Suppliers from nearly every state in the natio...   \n",
       "41  Mrs. Easterwood did a great job! https://t.co/...   \n",
       "60  The president wants to raid funding for our mi...   \n",
       "61  Proud to be a part of this group working to #K...   \n",
       "62  The president‚Äôs inability to fulfill his campa...   \n",
       "63                            https://t.co/h9MTeIoja3   \n",
       "64  RT @RepTedDeutch: Standing today and always wi...   \n",
       "65  Immigrants: bad\\nWhite Collar Crime: okay\\n\\nS...   \n",
       "66  Our job was to reach a deal, not deliver a win...   \n",
       "67  Proud to announce this federal funding to prov...   \n",
       "80  Happy #PresidentsDay, #GA12 https://t.co/qagMb...   \n",
       "81  Take a look at my e-Newsletter to see what I d...   \n",
       "82  Late Wednesday evening, my colleagues and I we...   \n",
       "83  I was very honored to join members of the Augu...   \n",
       "84  Thirteen grandkids later and she‚Äôs still my fo...   \n",
       "85  On the heels of a very impressive January #Job...   \n",
       "\n",
       "                                                 tags  \\\n",
       "0   [(‚Äú, NN), (If, IN), (the, DT), (Green, NNP), (...   \n",
       "1   [(If, IN), (we, PRP), (don, VBP), (‚Äô, JJ), (t,...   \n",
       "2   [(Anyone, NN), (who, WP), (thinks, VBZ), (our,...   \n",
       "3   [(‚Äú, JJ), (Republican, NNP), (Rep., NNP), (Ral...   \n",
       "4   [(Thank, NNP), (you, PRP), (to, TO), (@, VB), ...   \n",
       "5   [(I, PRP), (‚Äô, VBP), (m, RB), (thankful, JJ), ...   \n",
       "6   [(This, DT), (week, NN), (we, PRP), (salute, V...   \n",
       "7   [(If, IN), (President, NNP), (Trump, NNP), (ne...   \n",
       "8   [(I, PRP), (voted, VBD), (NO, NNP), (This, DT)...   \n",
       "9   [(As, IN), (a, DT), (pilot, NN), (I, PRP), (‚Äô,...   \n",
       "10  [(I, PRP), (couldn, VBP), (‚Äô, JJ), (t, NN), (a...   \n",
       "11  [(The, DT), (GreenNewDeal, NNP), (is, VBZ), (a...   \n",
       "12  [(Happy, JJ), (birthday, NN), (to, TO), (one, ...   \n",
       "13  [(@, NN), (NationalSheriff, NNP), (and, CC), (...   \n",
       "20  [(Congratulations, NNS), (Charlotte, NNP), (fo...   \n",
       "21  [(RT, NNP), (@, NNP), (nowthisnews, NNS), (Nea...   \n",
       "22  [(Today, NN), (for, IN), (BlackHistoryMonth, N...   \n",
       "23  [(As, IN), (the, DT), (@, NNP), (NBAAllStar, N...   \n",
       "24  [(See, VB), (my, PRP$), (official, JJ), (state...   \n",
       "25  [(Happy, JJ), (Valentine, NNP), ('s, POS), (Da...   \n",
       "26  [(Charities, NNS), (and, CC), (places, NNS), (...   \n",
       "27  [(Republicans, NNPS), (gave, VBD), (away, RB),...   \n",
       "28  [(RT, NNP), (@, NNP), (RepTedDeutch, NNP), (St...   \n",
       "29  [(House, NNP), (Democrats, NNPS), (promised, V...   \n",
       "30  [(RT, NNP), (@, NNP), (EdLaborCmte, NNP), (The...   \n",
       "31  [(Today, NN), (for, IN), (BlackHistoryMonth, N...   \n",
       "32  [(Unmarked, VBN), (burial, JJ), (grounds, NNS)...   \n",
       "33  [(This, DT), (bill, NN), (will, MD), (help, VB...   \n",
       "34  [(That, DT), (‚Äô, VBD), (s, JJ), (why, WRB), (t...   \n",
       "35  [(The, DT), (graves, NNS), (of, IN), (African,...   \n",
       "36  [(Standing, VBG), (with, IN), (the, DT), (memb...   \n",
       "37  [(I, PRP), (know, VBP), (firsthand, VBP), (tha...   \n",
       "38  [(During, IN), (today, NN), (‚Äô, NNP), (s, NN),...   \n",
       "39  [(9,268, CD), (people, NNS), (in, IN), (North,...   \n",
       "40  [(Suppliers, NNS), (from, IN), (nearly, RB), (...   \n",
       "41  [(Mrs., NNP), (Easterwood, NNP), (did, VBD), (...   \n",
       "60  [(The, DT), (president, NN), (wants, VBZ), (to...   \n",
       "61  [(Proud, NN), (to, TO), (be, VB), (a, DT), (pa...   \n",
       "62  [(The, DT), (president, NN), (‚Äô, NNP), (s, VBZ...   \n",
       "63             [(https, NN), (//t.co/h9MTeIoja3, NN)]   \n",
       "64  [(RT, NNP), (@, NNP), (RepTedDeutch, NNP), (St...   \n",
       "65  [(Immigrants, NNS), (bad, JJ), (White, NNP), (...   \n",
       "66  [(Our, PRP$), (job, NN), (was, VBD), (to, TO),...   \n",
       "67  [(Proud, NN), (to, TO), (announce, VB), (this,...   \n",
       "80  [(Happy, JJ), (PresidentsDay, NNP), (GA12, NNP...   \n",
       "81  [(Take, VB), (a, DT), (look, NN), (at, IN), (m...   \n",
       "82  [(Late, JJ), (Wednesday, NNP), (evening, NN), ...   \n",
       "83  [(I, PRP), (was, VBD), (very, RB), (honored, V...   \n",
       "84  [(Thirteen, NNP), (grandkids, NNS), (later, RB...   \n",
       "85  [(On, IN), (the, DT), (heels, NNS), (of, IN), ...   \n",
       "\n",
       "                                               tokens  retweet  \n",
       "0   [If, the, Green, New, Deal, becomes, a, realit...        0  \n",
       "1   [If, we, dont, stand, for, life, who, will, Wh...        0  \n",
       "2   [Anyone, who, thinks, our, crisis, at, the, bo...        0  \n",
       "3   [Republican, Rep, Ralph, Abraham, isnt, going,...        0  \n",
       "4   [Thank, you, to, WashTimes, for, allowing, Sen...        0  \n",
       "5   [Im, thankful, to, have, SecretarySonnys, supp...        0  \n",
       "6   [This, week, we, salute, the, more, than, 9, m...        0  \n",
       "7   [If, President, Trump, needs, to, declare, a, ...        0  \n",
       "8   [I, voted, NO, This, bill, limits, the, number...        0  \n",
       "9   [As, a, pilot, Ive, seen, firsthand, , from, t...        0  \n",
       "10  [I, couldnt, agree, more, with, my, colleague,...        0  \n",
       "11  [The, GreenNewDeal, is, a, socialists, wish, l...        0  \n",
       "12  [Happy, birthday, to, one, of, Americas, great...        0  \n",
       "13  [NationalSheriff, and, MCSheriffs, have, calle...        0  \n",
       "20  [Congratulations, Charlotte, for, a, great, NB...        0  \n",
       "21  [RT, nowthisnews, Nearly, 1200, children, were...        1  \n",
       "22  [Today, for, BlackHistoryMonth, we, honor, Dom...        0  \n",
       "23  [As, the, NBAAllStar, weekend, kicks, off, ton...        0  \n",
       "24  [See, my, official, statement, on, the, bipart...        0  \n",
       "25       [Happy, Valentines, Day, httpstco7lNvUfR0yx]        0  \n",
       "26  [Charities, and, places, of, worship, shouldnt...        0  \n",
       "27  [Republicans, gave, away, over, 1, TRILLION, i...        0  \n",
       "28  [RT, RepTedDeutch, Standing, today, and, alway...        1  \n",
       "29  [House, Democrats, promised, action, and, we, ...        0  \n",
       "30  [RT, EdLaborCmte, The, PaycheckFairness, Act, ...        1  \n",
       "31  [Today, for, BlackHistoryMonth, we, honor, Rub...        0  \n",
       "32  [Unmarked, burial, grounds, are, often, discov...        0  \n",
       "33  [This, bill, will, help, communities, preserve...        0  \n",
       "34  [Thats, why, today, during, BlackHistoryMonth,...        0  \n",
       "35  [The, graves, of, African, Americans, have, to...        0  \n",
       "36  [Standing, with, the, members, of, the, North,...        0  \n",
       "37  [I, know, firsthand, that, these, are, some, o...        0  \n",
       "38  [During, todays, hearing, I, asked, questions,...        0  \n",
       "39  [9268, people, in, North, Carolina, experience...        0  \n",
       "40  [Suppliers, from, nearly, every, state, in, th...        0  \n",
       "41  [Mrs, Easterwood, did, a, great, job, httpstco...        0  \n",
       "60  [The, president, wants, to, raid, funding, for...        0  \n",
       "61  [Proud, to, be, a, part, of, this, group, work...        0  \n",
       "62  [The, presidents, inability, to, fulfill, his,...        0  \n",
       "63                               [httpstcoh9MTeIoja3]        0  \n",
       "64  [RT, RepTedDeutch, Standing, today, and, alway...        1  \n",
       "65  [Immigrants, bad\\nWhite, Collar, Crime, okay\\n...        0  \n",
       "66  [Our, job, was, to, reach, a, deal, not, deliv...        0  \n",
       "67  [Proud, to, announce, this, federal, funding, ...        0  \n",
       "80   [Happy, PresidentsDay, GA12, httpstcoqagMbIxWri]        0  \n",
       "81  [Take, a, look, at, my, eNewsletter, to, see, ...        0  \n",
       "82  [Late, Wednesday, evening, my, colleagues, and...        0  \n",
       "83  [I, was, very, honored, to, join, members, of,...        0  \n",
       "84  [Thirteen, grandkids, later, and, shes, still,...        0  \n",
       "85  [On, the, heels, of, a, very, impressive, Janu...        0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tw_week[['text', 'tags', 'tokens', 'retweet']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https', 4371),\n",
       " ('rt', 1249),\n",
       " ('today', 658),\n",
       " ('amp', 460),\n",
       " ('president', 430),\n",
       " ('national', 305),\n",
       " ('congress', 300),\n",
       " ('emergency', 286),\n",
       " ('trump', 279),\n",
       " ('bill', 256)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for tags in df_tw_week['tags']:\n",
    "    word_set = set()\n",
    "    \n",
    "    for item in tags:\n",
    "        word = item[0].lower()\n",
    "        \n",
    "        if word in (global_stopwords + local_stopwords):\n",
    "            continue\n",
    "        else:\n",
    "            word_set.add(word)\n",
    "            \n",
    "    counter.update(word_set)\n",
    "\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 6249),\n",
       " ('https', 4391),\n",
       " ('today', 3070),\n",
       " ('amp', 2256),\n",
       " ('president', 1830),\n",
       " ('national', 1549),\n",
       " ('congress', 1488),\n",
       " ('emergency', 1382),\n",
       " ('bill', 1264),\n",
       " ('border', 1239),\n",
       " ('', 1160),\n",
       " ('house', 1132),\n",
       " ('great', 1125),\n",
       " ('one', 1093),\n",
       " ('us', 1084),\n",
       " ('act', 1083),\n",
       " ('thank', 1070),\n",
       " ('trump', 1055),\n",
       " ('new', 951),\n",
       " ('bipartisan', 946),\n",
       " ('happy', 926),\n",
       " ('people', 926),\n",
       " ('day', 916),\n",
       " ('year', 904),\n",
       " ('work', 876),\n",
       " ('im', 860),\n",
       " ('proud', 841),\n",
       " ('time', 804),\n",
       " ('support', 778),\n",
       " ('first', 768),\n",
       " ('families', 746),\n",
       " ('parkland', 745),\n",
       " ('community', 739),\n",
       " ('would', 733),\n",
       " ('need', 733),\n",
       " ('gun', 726),\n",
       " ('week', 706),\n",
       " ('last', 705),\n",
       " ('honor', 701),\n",
       " ('american', 700),\n",
       " ('security', 658),\n",
       " ('government', 653),\n",
       " ('presidents', 625),\n",
       " ('wall', 620),\n",
       " ('violence', 619),\n",
       " ('funding', 608),\n",
       " ('discuss', 604),\n",
       " ('join', 571),\n",
       " ('deal', 552),\n",
       " ('like', 540)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tokens in df_tw_week['tokens']:\n",
    "    tokens_set = set()\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        \n",
    "        if token in (global_stopwords + local_stopwords):\n",
    "            continue\n",
    "        else:\n",
    "            tokens_set.add(token)\n",
    "    \n",
    "    counter.update(tokens_set)\n",
    "        \n",
    "counter.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Members of House of Rep. and Their Twitter Names\n",
    "### No need to process below this cell.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### list of all memebers of House of Representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of HR members \n",
    "df_rep_members = pd.read_csv('US_House_116.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_members = df_rep_members[['Name', 'District']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_members['last_name'] = df_hrep_members['Name'].apply(lambda x: x.split(', ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_members.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_members.to_csv('output1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Twitter handles \n",
    "df_rep_twhandles = pd.read_csv('hrep_twitter_names.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twhandles['tw_handle'] = df_rep_twhandles['List members'].apply(lambda x: x.split('Verified'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_handles = []\n",
    "df_rep_twhandles['name'] = np.nan\n",
    "df_rep_twhandles['tw_name'] = np.nan\n",
    "for idx in range(0, len(df_rep_twhandles['tw_handle'])):\n",
    "    df_rep_twhandles['name'][idx] = df_rep_twhandles['tw_handle'][idx][0].strip()\n",
    "    \n",
    "    if len(df_rep_twhandles['tw_handle'][idx]) < 2:\n",
    "        group_handles.append(df_rep_twhandles['tw_handle'][idx][0])\n",
    "        continue\n",
    "    else:\n",
    "        df_rep_twhandles['tw_name'][idx] = \"@\" + df_rep_twhandles['tw_handle'][idx][1].strip().split('@')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twnames = df_rep_twhandles[['name', 'tw_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twnames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twnames['last_name'] = df_rep_twnames['name'].apply(lambda x: x.split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twnames.to_csv('output2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twnames['name'] = df_rep_twnames['name'].apply(lambda x: x.replace('Congressman', ''))\n",
    "df_rep_twnames['name'] = df_rep_twnames['name'].apply(lambda x: x.replace('Congresswoman', ''))\n",
    "df_rep_twnames['name'] = df_rep_twnames['name'].apply(lambda x: x.replace('Rep.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_twnames.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep = pd.merge(df_rep_members, df_rep_twnames, on=['last_name'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep.to_excel('output3.xlsx', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
